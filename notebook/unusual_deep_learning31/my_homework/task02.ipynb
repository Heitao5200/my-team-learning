{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task02 机器学习基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 基本概念\n",
    "\n",
    "- 概念：从已知数据中获得规律，并利用规律对未知数据进行预测\n",
    "- 分类：有监督学习、无监督学习、强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 数据集\n",
    "\n",
    "- 概念：观测样本的集合，$D=\\{x_1, x_2, \\dots, x_n\\}$，其中$d$为样本空间的维度\n",
    "- 分类：训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 误差分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 过拟合与欠拟合\n",
    "\n",
    "- 误差：训练误差、泛化误差、测试误差\n",
    "- 过拟合：能拟合训练样本，无法很好拟合测试样本，预防方式：减少参数、降低模型复杂度、正则化\n",
    "- 欠拟合：没有很好拟合训练样本，预防方式：调整参数、增加迭代深度、用更加复杂的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 泛化误差分析\n",
    "\n",
    "- 误差公式：$$\\text{Err}(\\hat{f})=\\text{Bias}^2 (\\hat{f})+\\text{Var}(\\hat{f})+\\sigma_{\\varepsilon}^2$$其中$\\varepsilon \\sim N(0,\\sigma_{\\varepsilon})$时噪声，潜在模型为$Y=f(x) + \\varepsilon$，估计模型为$\\hat{f}(X)$\n",
    "- 偏差：模型在样本上的期望结果与真实结果之间的差距，反映模型的拟合能力\n",
    "- 方差：模型在不同训练集中得到函数的输出结果与期望结果之间的误差，反映模型的波动情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 交叉验证\n",
    "\n",
    "- 基本思路：训练集划分为$K$份，其中一份作为验证集，其余$K-1$份作为训练集，模型在训练集上进行训练，在验证集上计算误差，对模型进行误差分析\n",
    "- 交叉验证方法：$K$折交叉验证、留一交叉验证、$K$折重复交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 有监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 基本概念\n",
    "\n",
    "- 学习任务：已知输出空间，训练一个模型用于预测$y$的取值，使得$f(x) \\cong y$\n",
    "- 分类：预测值是离散值\n",
    "- 回归：预测值是连续值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 线性回归\n",
    "\n",
    "- 概念：在样本属性和标签中找到一个线性关系，训练一个线性模型，使得预测值与样本标签的差值最小\n",
    "- 线性模型一般形式：$\\displaystyle f(x^{(k)}) = \\sum_{i=1}^m w_i x_i^{(k)} + b$\n",
    "- 优化目标：$\\displaystyle (w^*,b^*) =\\mathop{\\arg\\min} \\limits_{(w,b)} \\sum_{k = 1}^n(w^T x^{(k)}+b-y^{(k)})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 逻辑回归\n",
    "\n",
    "- 概念：利用sigmoid函数，将线性回归产生的预测值映射为0到1之间\n",
    "- 模型公式：\n",
    "$$\n",
    "g(f(x^{(k)}))=\\left\\{\n",
    "\\begin{array}{l}\n",
    "1, \\frac{1}{\\displaystyle 1+e^{-(w^T x^{(k)}+b)}}\\geq 0.5 \\\\ \n",
    "0, \\text{otherwise}\n",
    "\\end{array} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 支持向量机\n",
    "\n",
    "- 基本思想：对于线性可分的数据，找到一个位于两类训练样本正中心的超平面，使得margin最大化\n",
    "- 优化函数：\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "\\displaystyle & \\mathop{\\arg \\min} \\limits_{(w,b)} \\frac{1}{2}\\sum_{i = 1}^d w_i^2 \\\\ \n",
    "s.t. & \\forall x_i \\in D, |w^T x_i + b| \\geq 1\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 决策树\n",
    "\n",
    "- 概念：基于树结构进行决策的机器学习方法，树结构中，叶子节点给出类别，内部节点代表某个属性\n",
    "- 树的生成：ID3算法使用信息增益作为准则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 随机森林\n",
    "\n",
    "- 基本思路：创建多棵决策树，且每棵决策树之间无关联，根据多数原则决定样本分类结果\n",
    "- 构建步骤：\n",
    "  1. 随机有放回从训练集中抽取$m$个训练样本，创建训练集\n",
    "  2. 随机选择部分特征，创建决策树\n",
    "  3. 重复上述步骤，创建多棵决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 无监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 聚类\n",
    "\n",
    "- 基本思路：将数据分为多个类别，同一个类中对象的相似性较高，不同类中对象的差异性较大\n",
    "- 常见方法：K-Means聚类、均值漂移聚类、基于密度的聚类\n",
    "- K-Means聚类算法步骤：\n",
    "  1. 选取$K$个对象作为初始聚类中心\n",
    "  2. 计算样本数据与聚类中心的欧式距离，将数据按照聚类中心进行分类\n",
    "  3. 更新聚类中心，计算每个类别所有对象的均值，将其作为聚类中心，计算目标函数的值\n",
    "  4. 判断聚类中心和目标函数的值是否发生变化，没有变化则输出聚类结果，否则返回步骤2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 降维\n",
    "\n",
    "- 基本思路：将样本数据从维度$d$降低到更小的维度$m$，使得样本包含的信息量损失最小\n",
    "- 常见方法：PCA\n",
    "- 优势：\n",
    "  1. 数据在低纬度下更容易处理\n",
    "  2. 能显示重要特征\n",
    "  3. 能够进行可视化展示\n",
    "  4. 去除数据噪声，优化算法资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;本次任务，主要介绍了机器学习基本概念，分为有监督学习、无监督学习和强化学习；对于数据集，可划分为训练集、验证集和测试集，用于模型的训练和验证；通过误差分析能更好地了解模型泛化能力，计算偏差和方差，得到模型的误差程度，采用不同的方法避免过拟合和欠拟合。有监督学习主要介绍线性回归、逻辑回归、支持向量机、决策树和随机森林，无监督学习主要介绍聚类和降维。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
