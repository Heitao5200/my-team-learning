{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task03 基础实战（FashionMNIST时装分类）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 配置训练环境和超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用GPU环境\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置其他超参数\n",
    "batch_size = 256\n",
    "# 在Windows环境下，需要将num_workers改为0，否则会存在多线程问题\n",
    "num_workers = 0\n",
    "lr = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 数据读取和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 设置数据变换\n",
    "image_size = 28\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),   # 这一步取决于后续的数据读取方式，如果使用内置数据集则不需要\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集\n",
    "# csv数据下载链接：https://www.kaggle.com/zalando-research/fashionmnist\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28,28,1)\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255., dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用DataLoader类加载数据\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b39b49fcc8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = next(iter(train_loader))\n",
    "print(image.shape, label.shape)\n",
    "plt.imshow(image[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 模型设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用CNN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc(x)\n",
    "        # x = nn.functional.normalize(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 设置损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Adam优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 训练和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # 设置训练状态\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # 循环读取DataLoader中的全部数据\n",
    "    for data, label in train_loader:\n",
    "        # 将数据放到GPU用于后续计算\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        # 将优化器的梯度清0\n",
    "        optimizer.zero_grad()\n",
    "        # 将数据输入给模型\n",
    "        output = model(data)\n",
    "        # 设置损失函数\n",
    "        loss = criterion(output, label)\n",
    "        # 将loss反向传播给网络\n",
    "        loss.backward()\n",
    "        # 使用优化器更新模型参数\n",
    "        optimizer.step()\n",
    "        # 累加训练损失\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch): \n",
    "    # 设置验证状态\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    # 不设置梯度\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output, 1)\n",
    "            gt_labels.append(label.cpu().data.numpy())\n",
    "            pred_labels.append(preds.cpu().data.numpy())\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "    # 计算验证集的平均损失\n",
    "    val_loss = val_loss/len(test_loader.dataset)\n",
    "    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "    # 计算准确率\n",
    "    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\LearningDisk\\Learning_Projects\\MyPythonProjects\\my-team-learning\\venv\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.664049\n",
      "Epoch: 1 \tValidation Loss: 0.421500, Accuracy: 0.852400\n",
      "Epoch: 2 \tTraining Loss: 0.417311\n",
      "Epoch: 2 \tValidation Loss: 0.349790, Accuracy: 0.871200\n",
      "Epoch: 3 \tTraining Loss: 0.355448\n",
      "Epoch: 3 \tValidation Loss: 0.318987, Accuracy: 0.879500\n",
      "Epoch: 4 \tTraining Loss: 0.323644\n",
      "Epoch: 4 \tValidation Loss: 0.290521, Accuracy: 0.893800\n",
      "Epoch: 5 \tTraining Loss: 0.301900\n",
      "Epoch: 5 \tValidation Loss: 0.266420, Accuracy: 0.901300\n",
      "Epoch: 6 \tTraining Loss: 0.286696\n",
      "Epoch: 6 \tValidation Loss: 0.246448, Accuracy: 0.909700\n",
      "Epoch: 7 \tTraining Loss: 0.271441\n",
      "Epoch: 7 \tValidation Loss: 0.241845, Accuracy: 0.911200\n",
      "Epoch: 8 \tTraining Loss: 0.260185\n",
      "Epoch: 8 \tValidation Loss: 0.243311, Accuracy: 0.910800\n",
      "Epoch: 9 \tTraining Loss: 0.247986\n",
      "Epoch: 9 \tValidation Loss: 0.225896, Accuracy: 0.916200\n",
      "Epoch: 10 \tTraining Loss: 0.240718\n",
      "Epoch: 10 \tValidation Loss: 0.227848, Accuracy: 0.914700\n",
      "Epoch: 11 \tTraining Loss: 0.232358\n",
      "Epoch: 11 \tValidation Loss: 0.220180, Accuracy: 0.917500\n",
      "Epoch: 12 \tTraining Loss: 0.223933\n",
      "Epoch: 12 \tValidation Loss: 0.215308, Accuracy: 0.919400\n",
      "Epoch: 13 \tTraining Loss: 0.218354\n",
      "Epoch: 13 \tValidation Loss: 0.211890, Accuracy: 0.919300\n",
      "Epoch: 14 \tTraining Loss: 0.210027\n",
      "Epoch: 14 \tValidation Loss: 0.209707, Accuracy: 0.922700\n",
      "Epoch: 15 \tTraining Loss: 0.203024\n",
      "Epoch: 15 \tValidation Loss: 0.208233, Accuracy: 0.925600\n",
      "Epoch: 16 \tTraining Loss: 0.196965\n",
      "Epoch: 16 \tValidation Loss: 0.208209, Accuracy: 0.921900\n",
      "Epoch: 17 \tTraining Loss: 0.193155\n",
      "Epoch: 17 \tValidation Loss: 0.200000, Accuracy: 0.926100\n",
      "Epoch: 18 \tTraining Loss: 0.184376\n",
      "Epoch: 18 \tValidation Loss: 0.197259, Accuracy: 0.926200\n",
      "Epoch: 19 \tTraining Loss: 0.184272\n",
      "Epoch: 19 \tValidation Loss: 0.200259, Accuracy: 0.926000\n",
      "Epoch: 20 \tTraining Loss: 0.172641\n",
      "Epoch: 20 \tValidation Loss: 0.200177, Accuracy: 0.927100\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./FahionModel.pkl\"\n",
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
