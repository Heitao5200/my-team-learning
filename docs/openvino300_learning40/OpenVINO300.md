# OpenVINO高级课程

## 1 课程概览
在这次课程中，将深入学习OpenVINO，并了解基于OpenVINO生态系统的软件工具：
- 学习拓展资料：OpenModelZoo中经过深度优化的模型，提供很多C++和Python的Demo
- 异构系统设计
- 推理性能的优化方式
- 真正产品应用的重要性
- 低精度的模型校准
- 构建复杂的DL-Streamer流水线处理
- 音频和视频的处理及项目应用

## 2 第1课：OpenVINO核心组件资源和开发流程

### 2.1 OpenVINO套件架构
- 支持Intel架构的平台，包括Intel集成显卡、智能硬件等
- 传统计算机视觉工具：OpenCV、OpenVX，主要用于Intel CPU和集成显卡
- 工具包：Intel Media SDK（快速视频解码）、OpenCL驱动和运行环境，以及用于Linux的Optimize Intel FPGA运行环境等
- DLDT（深度学习部署套件）：模型优化器（支持各种模型转换，用于预处理，输出IR文件）和推理引擎（使用IR文件执行推理请求），IR文件包括xml文件（描述网络结构）和bin文件（参数权重）
- Open Model Zoo：提供预训练模型、示例、模型下载器
- 模型工具：Calibration Tool、Benchmark app、Model Analyzer、Accuracy Checker、Aux Capabilities
- DL Streamer：构建Gstreamer的视频分析流程
- OVMS：OpenVINO模型服务器，用于构建推理服务器
- Training extensions：提供模型的重训练
- DL WorkBench：基于可视化的Benchmarking应用工具

### 2.2 实验演示

- 3D Human Pose Demo：实时检测视频中多人的人体3D姿势，用于电影制作、零售、游戏、增强现实等场景，难点在于人体姿势中的小细节，比如：耳朵、眼睛、鼻子、肩膀、膝盖、衣服和灯光的变化，以及其他物体造成的遮挡。

- Colorization Demo：拍摄灰度图像，还原颜色并重新着色，颜色可增强图片效果，提升图像和视频的逼真度；难点是如何在颜色消失后，重新添加颜色。

- Audio Detection Demo：处理音频信号，基于DL-Streamer的声音检测和分类演示

- Formula Recognition：检测自由格式的手写公式或Latex公式的示例，通过Encoder（卷积神经网络）提取图像中的特征，主要是识别字母或图像的边界框，再使用Decoder查找符号。

- Mono-Depth Demo：从简单的2D图像中创建一个3D图像

- Object Detection Demo：对象检测演示

- BERT Question Answering Demo：使用BERT处理文本文件，智能问答演示

## 3 第2课：异构系统编程

- 加速器的故事：1985年能购买到386处理器，通过软件进行运算，速度会比较慢，在当时也可以购买i387DX处理器，作为外部加速器，提供了主处理器的额外运算能力，可以看作是Intel早期分布式算力系统的缩影；大约4年后，i387DX处理器被集成至CPU中，但是仍有一部分加速单元是独立的，必须在CPU的协同下工作，
- 不同设备的对比：
  1. CPU：可以运行的应用最广泛，具有最灵活的模型编辑，支持多种编程语言，具有需要调试和分析工具，但在3D渲染方面，不如专门的GPU
  2. GPU：执行3D渲染任务的速度更快更高效，不如CPU可运行的应用广泛，支持GPU的调试和分析工具相对较少
  3.  VPU：特定领域的加速器，在功率更低的设备中执行更高效的任务
  4.  FPGA：混合性解决方案，具有可编程，可像专用硬件一样，进行硬件加速
- 硬件加速器：专用于加速特定任务，加速器通常由CPU控制，CPU向加速器发送数据和运行指令，等待返回结果；期间会产生拷贝开销，数据传输成本较高
- 异构系统编程：
  1. 了解设备能力，可以使用评估工具，对设备进行评测
  2. 利用所有的系统资源，并平衡系统中的计算资源
  3. 考虑数据传输成本
- 异构编程原理：使用IR文件（与设备无关），通过推理引擎在不同设备上进行模型推理，提供灵活的插件架构，包括CPU插件（MKL-DNN）、GPU插件（cl-DNN）、MYRIAD插件（myriad）、FPGA插件（DLIA），也可以使用MULTI插件，在运行推理时，推理引擎会查看每个设备的利用率，根据该指标，决定模型在哪个设备上运行

## 4 第3课：AI应用中的视频加速处理

- 异构计算：目标是发挥系统的最大性能，提供最高的FPS、最快的响应速度、压缩尽可能多的待处理视频。
  1. 了解不同设备的任务负载情况，根据需求设计更高效的异构系统
  2. 最大程度减少速度传输：在Intel集成显卡中压缩视频，并给CPU返回已压缩的视频数据，将数据交给VPU进行推理
  3. 所有设备保持同步

- 第6代CPU的布局架构：GT2包括24个EU，GT3包括48个EU，GT4包括72个EU
- 其他功能：
  1. VDBox：提供BitStreamer的加速视频编解码
  2. VEBox：提供视频增强和帧处理操作的硬件加速
- Intel Media-SDK：提供C++/Python API、Gstreamer和OpenCV，加速视频编解码，提供视频处理，比如重新调整大小、转换等
- oneVPL（视频处理库）：逐步替代Media-SDK，不仅支持Intel CPU和GPU，并支持独立GPU和其他平台

## 5 第4课：OpenVINO推理性能

- 性能：
  1. 吞吐量：FPS（frames/sec）或(Inferences/sec)
  2. 延迟：处理一次推理所需的时间(Milliseconds)
  3. 效率：功耗、价格等
- 影响应用推理性能的参数：
  1. 网络参数：网络拓扑参数，各层输入的连接、图像大小等
  2. 设备参数：数据格式、内存大小、计算量
  3. 推理执行参数：通过benchmark_app.py指定执行参数
- 推理执行参数：
  1. 同步/异步执行
  2. Batch size：处理多个数据输入，更高的批次不一定会产生更高的性能，可能在内存过载时降低性能，可能会增加延迟
  3. 视频流的数量：在CPU吞吐量模式(Throughput Mode)下，线程将进行流分组，从而提升内核和内部资源的分配效率，流内部的同步开销更低，数据局部性更佳，有助于提高性能
  4. 线程数：将线程固定到特定核心
  5. 数据格式
  
## 6 第5课：AI推理中整数精度的推理

- 数据格式的性能影响：内存大小（1 FP32 = 4 INT8），可以将多个INT8进行打包，一并执行单指令多数据操作；SSE4.2可打包16个INT8，AVX2可打包32个INT8，AVX512可打包64个INT8
- 数据格式可以影响准确性：浮点数有非常宽的动态范围，整数的范围很窄
  1. 使用低精度的权重重新训练模型，可使用OpenVION training extensions进行重训练
  2. 转换模型精度：模型优化器可以执行简单的转换，例如FP32转为FP16
- 模型校准为整数的工具：DL Workbench、POT(Post-Training Optimization Tool)
- POT介绍：具有整套处理流程（reader -> Annotation conversion -> Pre-processing -> Launcher(INFERENCE) -> Calculate merics），提供两种模式（默认量化模式、准确性感知量化模式）

## 7 第6课：AI应用中的音频处理

- 图像处理：第1层（卷积层）用于提取图像特征，有时看起来像边缘图像；第2层将提取更高级别的特征....，应用多种尺寸的过滤器，处理缩放、旋转等，最后通过全连接层对图像进行分类，以上是视觉AI的简单描述
- 音频特征提取：信号采样和量化处理，使用傅里叶变换得到音频的频域表示，使用时域和频域叠加形成光谱图（MFCCs），转化为图像表示
- 音频处理：将音频信号转换为光谱图，从而转成类似于图像处理
- 影响音频处理的因素： 
  1. 信号具有可变长度，不同单词的长度差异很大，存在不同长度的停顿或静默时刻，需要确定一个时间窗口
  2. 语境、单词顺序很重要

## 8 第7课：DL-streamer表情和情绪识别

- DL-streamer的新功能：
  1. gvaTrack：添加跟踪元素
  2. gvaMetaConvert：将元数据转换为标准格式
  3. gvaMetaPublish：将此数据传达给其他流水线处理通道或应用
  4. gvaPython：构建自定义Python流水线处理通道元素
- 流水线处理：获取输入视频文件或摄像头或RTSP流、解码、准备推理、运行检测、分类或其他类型的推理
- 流水线处理通道的管理方式：
  1. GST 缓冲区是一种保存帧信息的数据结构，每个流水线处理通道阶段都可以读取gst缓冲区信息用于输入，并可以将信息添加到缓冲区用于输出
  2. 当添加跟踪流水线处理通道阶段时，会查看之前流水线处理通道阶段检测并存储在GST缓冲区中的所有对象并跟踪它们
- 智慧城市示例：
  - 基本架构：设想一下，城市遍布数百、甚至数千个摄像头所有这些摄像头都需要与城市指挥中心通信，假设每6个摄像头与“路口的交互计算机”或“节点”通信，并且每几个交互计算机 都保持与街区的节点进行通信，所有街区都要与城市的云指挥中心通信
  - 场景举例：1号摄像头检测到一张新面孔，并将该信息传输到上游的交互口，交互计算机将提取此面孔的特征，并将其传输给街区计算机，街区节点将从所有交互口计算机 收集输入信息并将其传输至指挥中心。指挥中心可能向下游传达某面孔是嫌疑人的信息，或请求以更高分辨率传输特定摄像头的数据。
- MQTT：使用broker来控制所有通信，每个客户端都可以向broker发送和发布消息，每条消息都属于一个Topic，并且broker知道将消息发送给每个订阅了相应Topic的客户（类似于消息发布与订阅）

## 9 第8课：整合实现AI应用中的音视频处理

- 应用场景描述：建立一个视频分析管道和可处理音频的并行管道，并在2个管道之间交换数据
- 挑战：
  1. 如何在2个管道之间交换数据
  2. 如何对事件进行时间同步
- 初步技术方案：通过共享文件传输的数据，一个管道将`gvaMetapublish`用于临时文件，另一个管道可以读取数据
- 流水线处理的管道连接原理：数据从左到右流动，这些管道阶段可以进行相互连接，使用`pads`进行连接，每个管道阶段都有一个` source pad`，用于输出该阶段的数据，每个阶段都有一个接收前一阶段数据的`sink-pad`，一个管道阶段可以有2个用于输出的源，或2个接收端， 
至于数量时，2个输出或2个输入是根据每个管道的功能而决定的
- 技术方案：两个流水线共享一个或多个解码阶段，故该处理流程有一个视频管道、一个音频管道和一个解码管道，将解码管道连接到音频管道和视频管道，音频检测结果发送到一个临时文件中，视频管道结果总是会写入GST缓冲区
- 具体方式：构建一个自定义 python 脚本，该脚本将从临时文件中读取音频结果，将它们与帧同步，并将检测元素添加到GST缓冲区，以便 视频管道的其余部分也可以呈现音频事件
- 方案步骤：
  1. 建立一个复杂的管道，用于处理视频和音频
  2. 对视频应用进行对象检测 
  3. 使用`ACLnet`对音频进行声音分类

## 10 课程总结

- 第1课：介绍了OpenVINO的整个生态系统，包括加速视频处理的媒体软件开发套件、VPL一个优秀快速的视频处理库、深度学习部署工具套件（DLDT）、Open Model Zoo、校准工具、DL-Streamer、DL-workbench。
- 演示运行流程：
  1. 先使用模型下载器下载模型，从模型列表找到需要下载的模型
  2. 如果需要，调用相同模型列表上的转换器脚本，将模型转换为IR
  3. 确保已经完成实验的准备工作，同时也可能需要满足其他额外的系统要求
  4. 运行演示
- 第2课：介绍加速器相关内容，并将加速器和功能进行了匹配学习，通过异构设备编程，可以在最高效的设备上执行每个任务，特别是计算密集度高的任务
- 第3课：介绍了英特尔集成GPU，使用媒体软件开发套件，用于在Intel CPU、GPU上以及未来在更多设备上进行视频处理，oneVPL 在这方面正逐步取代媒体软件开发套件
- 第4课：介绍推理性能，吞吐量延迟和其他效率参数的定义，介绍了执行参数，以及同步或异步运行推理的区别，并了解批处理的影响、并行推理请求的数量、线程、流等
- 第5课：深入解释了将模型转换为较低精度的优势和潜在问题，推荐将INT8用于支持英特尔DL-boost的多核机器，以便带来更大的性能提升
- 第6课：介绍音频处理内容，比较音频与视频的区别， 以及如何给神经网络提取音频特征，通过构建一个比较典型的音频管道，使用光谱图作为推理阶段的输入，用于检测声音或对声音分类
- 第7课：介绍了DL-streamer的一些新功能，包括跟踪功能、使用gvaPython创建自定义处理管道阶段、GST缓冲区和所有管道阶段相互传达数据的机制、将元数据转换为用户友好型格式、在本地或通过互联网发布相关数据
- 第8课：使用DL-streamer创建了一个完整的应用，用于并行处理图像和声音检测