# Task10 GCN

- GCN的基本思路：对于每个节点，从它的所有邻域节点处获取其特征信息，当然也包括它自身的特征。假设使用`average()`函数，对所有的节点进行该操作。最后，将这些计算得到的平均值输入到神经网络中。
- GCN图神经网络层函数：
$$
h_v^{(l)} = \sigma \left ( \sum_{u \in N(v)} \frac{h_u^{(l - 1)}}{|N(v)|} \right)
$$
可分别写成消息计算和消息聚合的形式：
$$
m_u^{(l)} = \frac{1}{|N(v)|} W^{(l)} h_u^{(l - 1)} \\
h_v^{(l)} = \sigma \left( \text{Sum} \left(\{ m_u^{(l)}, u \in N(v)\} \right) \right)
$$

# Task11 GraphSAGE

- GraphSAGE的基本思路：包含采样和聚合，首先使用节点之间连接信息，对邻域进行采样，然后通过多层聚合函数`AGG`不断地将相邻节点的信息融合在一起，用融合后的信息预测节点标签。
- GraphSAGE神经网络层函数：
$$
h_v^{(l)} = \sigma \left( W^{(l)} \cdot \text{CONCAT} \left( h_v^{(l - 1)}, \text{AGG} \left( \{ h_u^{(l - 1)}, \forall u \in N(v) \} \right) \right) \right)
$$
可分别写成消息计算和消息聚合的形式：
$$
h_{N(v)}^{(l)} = \text{AGG} \left( \{ h_u^{(l - 1)}, \forall u \in N(v) \} \right) \\
h_v^{l} = \sigma \left( W^{(l)} \cdot \text{CONCAT} \left( h_v^{(l - 1)}, h_{N(v)}^{(l)} \right) \right)
$$

可以使用不同的聚合函数：
- Mean：$\displaystyle \text{AGG} = \sum_{u \in N(v)} \frac{h_u^{(l - 1)}}{|N(v)|}$
- Pool：$\displaystyle \text{AGG} = \text{Mean} (\{ \text{MLP} (h_u^{(l - 1)}), \forall u \in N(v) \})$
- LSTM：$\displaystyle \text{AGG} = \text{LSTM} ([ h_u^{(l- 1)}, \forall u \in \pi (N(v))])$

# Task12 GAT

- GAT的基本思路：在聚合邻域信息时，考虑不同邻域的权重信息，然后将这些邻域信息按照注意力分数进行信息加权，根据注意力机制，其中$Q$是当前节点的特征向量，$K$就是邻域的特征向量，$V$是邻域经过$W$映射后的特征向量，计算注意力分数时，使用自身节点的特征向量分别与邻居节点的特征向量进行内积计算得到分数，然后将分数归一化，分别乘以对应的节点特征向量进行加权操作。
- GAT神经网络层函数：
$$
h_v^{(l)} = \sigma \left( \sum_{u \in N(v)} \alpha_{vu} W^{(l)} h_u^{(l - 1)} \right)
$$
其中，$\displaystyle \alpha_{vu} = \frac{1}{|N(v)|}$是节点$u$的消息对节点$v$的权重因子，不同邻居带来的信息权重相同（即连接权重相同）
